{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/jacklee20151/crm/blob/master/test.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "WBQlJz3Ugab0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "0c93131c-389d-4588-91b1-dcca51d7b3d1"
      },
      "cell_type": "code",
      "source": [
        "#!/usr/bin/python\n",
        "#coding=utf-8\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "import numpy as np\n",
        "from sklearn import tree\n",
        "from sklearn import svm\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "import numpy as np\n",
        "def f(x1, x2):\n",
        "    y = 0.5 * np.sin(x1) + 0.5 * np.cos(x2)  + 0.1 * x1 + 3\n",
        "    return y\n",
        "\n",
        "def load_data():\n",
        "    x1_train = np.linspace(0,50,500)\n",
        "    x2_train = np.linspace(-10,10,500)\n",
        "    data_train = np.array([[x1,x2,f(x1,x2) + (np.random.random(1)-0.5)] for x1,x2 in zip(x1_train, x2_train)])\n",
        "    x1_test = np.linspace(0,50,100)+ 0.5 * np.random.random(100)\n",
        "    x2_test = np.linspace(-10,10,100) + 0.02 * np.random.random(100)\n",
        "    data_test = np.array([[x1,x2,f(x1,x2)] for x1,x2 in zip(x1_test, x2_test)])\n",
        "    return data_train, data_test\n",
        "\n",
        "def main(_):\n",
        "    data = load_data()\n",
        "    #print(data)\n",
        "    x_train = data[0]\n",
        "    clf = DecisionTreeRegressor()\n",
        "    \n",
        "    \n",
        "    X = [[0, 0,5,6,6,7,777,6], [2, 2,9,0,11,33,22,66]]\n",
        "    y = [0.5, 2.5]\n",
        "    clf1 = tree.DecisionTreeRegressor()\n",
        "    clf1 = clf.fit(X, y)\n",
        "    a= clf1.predict([[1, 5,6,6,7,4,6,3]])\n",
        "    print(a)\n",
        "    \n",
        "    \n",
        "    X2 = [[0, 0,6,7], [1, 1,6,5], [5, 6,7,8], [6, 6,7,8]]\n",
        "    y2 = [0, 1,5,7]\n",
        "    clf2 = svm.SVR()\n",
        "    clf2.fit(X2, y2)\n",
        "    b= clf2.predict([[0,0,7,9]])\n",
        "    print(b)\n",
        "    print(clf2.support_vectors_)\n",
        "    \n",
        "    \n",
        "    X = [[0., 0.], [1., 1.]]\n",
        "    y = [0, 1]\n",
        "    clf3 = SGDClassifier(loss=\"hinge\", penalty=\"l2\")\n",
        "    clf3.fit(X, y)\n",
        "    c = clf3.predict([[2., 2.]])\n",
        "    print(c)\n",
        "    print(clf3.coef_ )\n",
        "    print(clf3.intercept_)\n",
        "\n",
        "    aa = np.array([[1,2,3],[3,4,5]])\n",
        "    print(aa)\n",
        "    bb = np.array([[9,8], [7,6], [10,11]])\n",
        "    print(bb)\n",
        " \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #clf.fit(x_train, y_train)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main(0)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.5]\n",
            "[2.42700832]\n",
            "[[0. 0. 6. 7.]\n",
            " [1. 1. 6. 5.]\n",
            " [5. 6. 7. 8.]\n",
            " [6. 6. 7. 8.]]\n",
            "[1]\n",
            "[[9.91080278 9.91080278]]\n",
            "[-9.99002993]\n",
            "[[1 2 3]\n",
            " [3 4 5]]\n",
            "[[ 9  8]\n",
            " [ 7  6]\n",
            " [10 11]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "8VE6pUnWgjgk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    }
  ]
}